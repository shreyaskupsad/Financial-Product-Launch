{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Run this entire section to train the model with given dataset"
      ],
      "metadata": {
        "id": "UJ45If8CjDIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the individual dataset\n",
        "!wget -O cwk_data_20535493.csv \"https://drive.google.com/uc?export=download&id=1Bu5Lge14q5fL0uvOGWutwT5yj6y0Vfla\""
      ],
      "metadata": {
        "id": "yZ2dxDlhjQWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset filename\n",
        "filename = \"cwk_data_20535493.csv\""
      ],
      "metadata": {
        "id": "YMaoI4CejV4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_dataset(filename):\n",
        "\n",
        "  import pandas as pd\n",
        "  # Read the csv file\n",
        "  data = pd.read_csv(filename)\n",
        "\n",
        "  #count of unknowns for each field and their share in that particular field\n",
        "  columns_to_drop = []\n",
        "\n",
        "  for col in data.columns:\n",
        "      unknown_cnt = data[col].value_counts().get('unknown', 0)  # Use get() to handle the case where 'unknown' doesn't exist\n",
        "      unknown_pct = (unknown_cnt / data[col].count()) * 100\n",
        "      print(f'Field: {col}    Unknown Count: {unknown_cnt}   Unknown Percentage: {unknown_pct:.2f}%')\n",
        "      if unknown_pct > 50:\n",
        "        columns_to_drop.append(col)\n",
        "\n",
        "  if len(columns_to_drop) == 0:\n",
        "      print('No column needs to be fully dropped as the proportion of unknown values are not very high for any given column.')\n",
        "  else:\n",
        "     print('\\n\\nColumns to be dropped:\\n {}'.format(columns_to_drop))\n",
        "\n",
        "  # Check if columns in 'columns_to_drop' exist before dropping\n",
        "  columns_to_drop_existing = [col for col in columns_to_drop if col in data.columns]\n",
        "\n",
        "  # Drop the unwanted columns (if they exist)\n",
        "  if columns_to_drop_existing:\n",
        "     data_cleansed = data.drop(columns=columns_to_drop_existing, axis=1)\n",
        "  else:\n",
        "     data_cleansed = data.copy()\n",
        "\n",
        "  # Now 'data_cleansed' contains the dataset with unwanted columns dropped (if they existed)\n",
        "\n",
        "  #Replace the 'unknown' values in remaining fields by the mode of their field\n",
        "  for col in data_cleansed.columns:\n",
        "    mode = data_cleansed.mode()[col][0]\n",
        "    print('Field: {}, Mode: {}'.format(col,mode))\n",
        "    data_cleansed.loc[data_cleansed[col] == 'unknown',[col]] = mode\n",
        "    unknown_count = data_cleansed[col].value_counts().get('unknown', 0)\n",
        "    print(f'Count of unknowns for {col} after replacing: {unknown_count}')\n",
        "\n",
        "  # Check if 'duration' is in the columns before dropping\n",
        "  if 'duration' in data_cleansed.columns:\n",
        "      model_data = data_cleansed.drop('duration', axis=1)\n",
        "  else:\n",
        "      model_data = data_cleansed.copy()\n",
        "\n",
        "  print('Success')\n",
        "\n",
        "  return model_data\n"
      ],
      "metadata": {
        "id": "37FGKECercLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, make_scorer, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "model_data = clean_dataset(filename)\n",
        "\n",
        "output_feature = 'y'\n",
        "\n",
        "# Separate numerical and categorical features\n",
        "numerical_features = model_data.select_dtypes(include=['int64', 'float64'])\n",
        "categorical_features = model_data.iloc[:, :-1].select_dtypes(include=['object'])\n",
        "\n",
        "# Label encode the categorical features\n",
        "for col in categorical_features.columns:\n",
        "    categorical_features[col] = categorical_features[col].astype('category').cat.codes\n",
        "\n",
        "# Concatenate numerical and modified categorical features\n",
        "features = pd.concat([numerical_features, categorical_features], axis=1)\n",
        "\n",
        "# Split the data into features (X) and target variable (y)\n",
        "X = features\n",
        "y = model_data[output_feature]"
      ],
      "metadata": {
        "id": "20xcv8YmrQnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Apply Random Forest model with the best parameters\n",
        "rf_model = RandomForestClassifier(\n",
        "    class_weight='balanced',\n",
        "    max_depth=None,\n",
        "    max_features='log2',\n",
        "    min_samples_leaf=10,\n",
        "    min_samples_split=15,\n",
        "    n_estimators=100,\n",
        "    random_state=42  # Add a random state for reproducibility\n",
        ")\n",
        "\n",
        "# Fit the model to the entire dataset\n",
        "rf_model.fit(X, y)\n",
        "\n",
        "# Make predictions on the entire dataset\n",
        "y_pred_rf = rf_model.predict(X)\n",
        "\n",
        "# Calculate and display various metrics on the entire dataset\n",
        "accuracy_rf = accuracy_score(y, y_pred_rf)\n",
        "precision_rf = precision_score(y, y_pred_rf, pos_label='yes')\n",
        "recall_rf = recall_score(y, y_pred_rf, pos_label='yes')\n",
        "f1_rf = f1_score(y, y_pred_rf, pos_label='yes')\n",
        "\n",
        "# Display Confusion Matrix\n",
        "cm_rf = confusion_matrix(y, y_pred_rf)\n",
        "plt.figure(figsize=(5, 4))\n",
        "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=rf_model.classes_, yticklabels=rf_model.classes_)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix (Random Forest)')\n",
        "plt.show()\n",
        "\n",
        "# Display the classification report\n",
        "print('\\nClassification Report:')\n",
        "print(classification_report(y, y_pred_rf, target_names=['no', 'yes']))"
      ],
      "metadata": {
        "id": "8zTSf_1Nkqed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def final_model_prediction(test_data_file_name):\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "  from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "  from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, make_scorer, confusion_matrix\n",
        "  import matplotlib.pyplot as plt\n",
        "  import pandas as pd\n",
        "  import seaborn as sns\n",
        "\n",
        "  model_data = clean_dataset(test_data_file_name)\n",
        "\n",
        "  output_feature = 'y'\n",
        "\n",
        "  # Separate numerical and categorical features\n",
        "  numerical_features = model_data.select_dtypes(include=['int64', 'float64'])\n",
        "  categorical_features = model_data.iloc[:, :-1].select_dtypes(include=['object'])\n",
        "\n",
        "  # Label encode the categorical features\n",
        "  for col in categorical_features.columns:\n",
        "      categorical_features[col] = categorical_features[col].astype('category').cat.codes\n",
        "\n",
        "  # Concatenate numerical and modified categorical features\n",
        "  features = pd.concat([numerical_features, categorical_features], axis=1)\n",
        "\n",
        "  # Split the data into features (X) and target variable (y)\n",
        "  X = features\n",
        "  y = model_data[output_feature]\n",
        "\n",
        "  # Predict the test dataset outcomes using the model trained earlier - rf_model\n",
        "  y_test_pred = rf_model.predict(X)\n",
        "\n",
        "  # Calculate and display various metrics on the entire dataset\n",
        "  accuracy_rf = accuracy_score(y, y_test_pred)\n",
        "  precision_rf = precision_score(y, y_test_pred, pos_label='yes')\n",
        "  recall_rf = recall_score(y, y_test_pred, pos_label='yes')\n",
        "  f1_rf = f1_score(y, y_test_pred, pos_label='yes')\n",
        "\n",
        "  # Display Confusion Matrix\n",
        "  cm_rf = confusion_matrix(y, y_test_pred)\n",
        "  plt.figure(figsize=(5, 4))\n",
        "  sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=rf_model.classes_, yticklabels=rf_model.classes_)\n",
        "  plt.xlabel('Predicted')\n",
        "  plt.ylabel('Actual')\n",
        "  plt.title('Confusion Matrix (Random Forest)')\n",
        "  plt.show()\n",
        "\n",
        "  # Display the classification report\n",
        "  print('\\nClassification Report:')\n",
        "  print(classification_report(y, y_pred_rf, target_names=['no', 'yes']))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OyeWeJFPoSMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Upload and enter the test file name"
      ],
      "metadata": {
        "id": "fCkQInILlKZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the test file and provide the name of the file in the quotes below\n",
        "test_data_file_name = 'your file name please'"
      ],
      "metadata": {
        "id": "A44Uj5WrlNex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run this section to get the predictions on test dataset"
      ],
      "metadata": {
        "id": "KXayISoCsbjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_model_prediction(test_data_file_name)"
      ],
      "metadata": {
        "id": "B3afhQttsNfG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}